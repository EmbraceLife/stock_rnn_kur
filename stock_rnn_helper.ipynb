{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-06T16:40:57.306721",
     "start_time": "2017-03-06T16:40:57.294621"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stock_rnn_helper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stock_rnn_helper.py\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    print('yo')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        \n",
    "                                                            # create stop drawing spaces or empty points for each window\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "                                                            # draw from start, but very first part is empty drawing\n",
    "                                                            # the visual part is real window prediction data\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "#         plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# how to load stockdata csv file\n",
    "def make_data(filename, seq_len, normalise_window):\n",
    "                                                        # make it a long list of numbers\n",
    "    f = open(filename, 'r').read()\n",
    "    data = f.split('\\n')\n",
    "                                                        # make it a list of lists (each list is a sequence)\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    \n",
    "                                                        # normalize each number\n",
    "    if normalise_window:\n",
    "        result = normalise_windows(result)\n",
    "                                                        # turn the normalized lists into arrays\n",
    "    result = np.array(result)\n",
    "                                                        # take 90% of rows of data as training set\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "                                                        # shuffle the training set, and split train_x and train_y\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "                                                        # get test_x and test_y\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "                                                        # Question: reshape train and test into 3-d dim\n",
    "                                                        # (num_data_point, seq_len, 1)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "\n",
    "\n",
    "                                                        # normalize the list of lists\n",
    "def normalise_windows(window_data):\n",
    "                                                        # create an empty list\n",
    "    normalised_data = []\n",
    "                                                        # for each element list \n",
    "    for window in window_data:\n",
    "                                                        # get each number of element list, divide the first number of the \n",
    "                                                        # element list, then minus 1, save this new window in a new list\n",
    "                                                        # QUESTION: why use 1st number of each window/element list, not first\n",
    "                                                        # number of the entire dataset?                   \n",
    "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "                                                        # store all normalized windows into a new list \n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data\n",
    "\n",
    "\n",
    "\n",
    "                                                        # build LSTM model to predict\n",
    "def build_model(layers):                                # layers is a list [input_dim, h1_dim, h2_dim, out_dim]\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))                         # output all values of the sequence\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))                        # output last value of the sequence\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))                          # Question: kur is very alike keras, is kur just made a wrapper over keras\n",
    "                                                        # kur access tensorflow through keras, not using TF code directly, right? \n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def predict_point_by_point(model, data):\n",
    "                                                        # Predict each timestep given the last sequence of true data, \n",
    "                                                        # in effect only predicting 1 step ahead each time\n",
    "    predicted = model.predict(data)\n",
    "                                                        # convert predicted from 1-d to 2-d\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "                                                        # QUESTION: I don't understand how the functions below work\n",
    "                                                        # but they work, just use them first\n",
    "\n",
    "def predict_sequence_full(model, data, window_size):\n",
    "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(round(len(data)/prediction_len)-1)):\n",
    "        \n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
